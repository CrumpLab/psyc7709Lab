[{"path":"index.html","id":"welcome","chapter":"1 Welcome","heading":"1 Welcome","text":"textbook .’m sure stuff showing like ?1","code":""},{"path":"index.html","id":"another-thing","chapter":"1 Welcome","heading":"1.1 Another thing","text":"need ?2","code":""},{"path":"t-tests.html","id":"t-tests","chapter":"2 T-tests","heading":"2 T-tests","text":"","code":""},{"path":"t-tests.html","id":"overview","chapter":"2 T-tests","heading":"2.1 Overview","text":"lab demonstrates conduct one sample, paired sample, independent sample t-tests R, uses R tool develop insight conceptual foundations t-test.","code":""},{"path":"t-tests.html","id":"historical-background","chapter":"2 T-tests","heading":"2.2 Historical Background","text":"William Sealy Gosset published t-test pseudonym “Student”, test sometimes called “Student’s t-test” (Student, 1908). dispute origin meaning \\(t\\). One hypothesis \\(s\\) commonly used time refer sample statistics, Gosset chose \\(t\\) next letter, perhaps indicating “step-” thinking sample statistics? Gosset published pseudonym employee Guinness Breweries time, hired examine issues making inferences small samples brewing beer. test developed intellectual property Guinness, Gosset thought test broadly used, published pseudonym protect job. Pearson (1939) provides biography Gosset. Sawilowsky & Blair (1992) conduct simulations examine robust t-test violations assumptions.","code":""},{"path":"t-tests.html","id":"practical-i-t.test","chapter":"2 T-tests","heading":"2.3 Practical I: t.test()","text":"Base R includes t.test() function computes several forms t-tests.three quick examples computing one sample, paired sample independent sample t-tests using R.","code":"\n?t.test"},{"path":"t-tests.html","id":"one-sample-t-test","chapter":"2 T-tests","heading":"2.3.1 One-sample t-test","text":"","code":"\nsome_random_means <- rnorm(10,0,1)\nt.test(some_random_means, mu=0)## \n##  One Sample t-test\n## \n## data:  some_random_means\n## t = -2.1418, df = 9, p-value = 0.06085\n## alternative hypothesis: true mean is not equal to 0\n## 95 percent confidence interval:\n##  -1.33604999  0.03652445\n## sample estimates:\n##  mean of x \n## -0.6497628"},{"path":"t-tests.html","id":"paired-sample-t-test","chapter":"2 T-tests","heading":"2.3.2 Paired-sample t-test","text":"","code":"\nA_means <- rnorm(10,0,1)\nB_means <- rnorm(10,0,1)\n\nt.test(A_means,B_means,paired=TRUE)## \n##  Paired t-test\n## \n## data:  A_means and B_means\n## t = -0.39973, df = 9, p-value = 0.6987\n## alternative hypothesis: true difference in means is not equal to 0\n## 95 percent confidence interval:\n##  -1.3231131  0.9257331\n## sample estimates:\n## mean of the differences \n##                -0.19869"},{"path":"t-tests.html","id":"independent-sample-t-test","chapter":"2 T-tests","heading":"2.3.3 Independent-sample t-test","text":"","code":"\nA_means <- rnorm(10,0,1)\nB_means <- rnorm(10,0,1)\n\nt.test(A_means,B_means, var.equal=TRUE)## \n##  Two Sample t-test\n## \n## data:  A_means and B_means\n## t = 0.057046, df = 18, p-value = 0.9551\n## alternative hypothesis: true difference in means is not equal to 0\n## 95 percent confidence interval:\n##  -1.110011  1.171974\n## sample estimates:\n##  mean of x  mean of y \n## -0.2948039 -0.3257852"},{"path":"t-tests.html","id":"formula-syntax-for-data-frames","chapter":"2 T-tests","heading":"2.3.4 formula syntax for data frames","text":"examples, t.test() function applied vectors containing sample means. also possible apply t.test() function long data frames using ~ syntax.","code":"\nmy_data <- data.frame(group = rep(c(\"A\",\"B\"), each=10),\n                      means = rnorm(20,0,1))\n\nt.test(means~group, var.equal=TRUE, data=my_data)## \n##  Two Sample t-test\n## \n## data:  means by group\n## t = 1.1405, df = 18, p-value = 0.269\n## alternative hypothesis: true difference in means is not equal to 0\n## 95 percent confidence interval:\n##  -0.5582661  1.8841038\n## sample estimates:\n## mean in group A mean in group B \n##       0.3088346      -0.3540843"},{"path":"t-tests.html","id":"one-or-two-sided-test","chapter":"2 T-tests","heading":"2.3.5 one or two-sided test","text":"default, t.test() function provides two sided test, options can specified using alternative = c(\"two.sided\", \"less\", \"greater\") input parameter.","code":"\nsome_random_means <- rnorm(10,0,1)\nt.test(some_random_means, mu=0, alternative = \"two.sided\")## \n##  One Sample t-test\n## \n## data:  some_random_means\n## t = 1.0856, df = 9, p-value = 0.3059\n## alternative hypothesis: true mean is not equal to 0\n## 95 percent confidence interval:\n##  -0.3438763  0.9784597\n## sample estimates:\n## mean of x \n## 0.3172917\nt.test(some_random_means, mu=0, alternative = \"less\")## \n##  One Sample t-test\n## \n## data:  some_random_means\n## t = 1.0856, df = 9, p-value = 0.8471\n## alternative hypothesis: true mean is less than 0\n## 95 percent confidence interval:\n##       -Inf 0.8530616\n## sample estimates:\n## mean of x \n## 0.3172917\nt.test(some_random_means, mu=0, alternative = \"greater\")## \n##  One Sample t-test\n## \n## data:  some_random_means\n## t = 1.0856, df = 9, p-value = 0.1529\n## alternative hypothesis: true mean is greater than 0\n## 95 percent confidence interval:\n##  -0.2184782        Inf\n## sample estimates:\n## mean of x \n## 0.3172917"},{"path":"t-tests.html","id":"var.equal-and-welchs-correction","chapter":"2 T-tests","heading":"2.3.6 var.equal and Welch’s correction","text":"t.test() function also makes default assumptions indpendent samples test. , default applies correction called Welch’s correction. correction related assumption equal variances samples group.conduct t-test without correction set var.equal=TRUE. applies independent sample case two variances.","code":"\nA <- rnorm(10,0,1)\nB <- rnorm(10,0,1)\nt.test(A,B)## \n##  Welch Two Sample t-test\n## \n## data:  A and B\n## t = 0.28018, df = 14.327, p-value = 0.7833\n## alternative hypothesis: true difference in means is not equal to 0\n## 95 percent confidence interval:\n##  -0.8205231  1.0677183\n## sample estimates:\n##  mean of x  mean of y \n## -0.4144857 -0.5380833\nt.test(A,B, var.equal=TRUE)## \n##  Two Sample t-test\n## \n## data:  A and B\n## t = 0.28018, df = 18, p-value = 0.7825\n## alternative hypothesis: true difference in means is not equal to 0\n## 95 percent confidence interval:\n##  -0.8031948  1.0503900\n## sample estimates:\n##  mean of x  mean of y \n## -0.4144857 -0.5380833"},{"path":"t-tests.html","id":"t.test-contents","chapter":"2 T-tests","heading":"2.3.7 t.test() contents","text":"t.test() function two kinds outputs. First, prints results console (saw ). Second, outputs list containing components test. individual pieces t-test can saved accessed putting results t.test new variable.example:","code":"\n (my_results <- t.test(A,B, var.equal=TRUE))## \n##  Two Sample t-test\n## \n## data:  A and B\n## t = 0.28018, df = 18, p-value = 0.7825\n## alternative hypothesis: true difference in means is not equal to 0\n## 95 percent confidence interval:\n##  -0.8031948  1.0503900\n## sample estimates:\n##  mean of x  mean of y \n## -0.4144857 -0.5380833\nmy_results$statistic##         t \n## 0.2801802\nmy_results$parameter## df \n## 18\nmy_results$p.value## [1] 0.7825338\nmy_results$estimate##  mean of x  mean of y \n## -0.4144857 -0.5380833"},{"path":"t-tests.html","id":"papaja-reporting-with-apa_print","chapter":"2 T-tests","heading":"2.3.8 papaja reporting with apa_print()","text":"papaja package convenient functions automating writing t-test results.example, t-test result, \\(t(18) = 0.28\\), \\(p = .783\\), printed using r code snippet inserted text .Rmd.","code":"\nlibrary(papaja)\napa_print(my_results)## $estimate\n## [1] \"$\\\\Delta M = 0.12$, 95\\\\% CI $[-0.80$, $1.05]$\"\n## \n## $statistic\n## [1] \"$t(18) = 0.28$, $p = .783$\"\n## \n## $full_result\n## [1] \"$\\\\Delta M = 0.12$, 95\\\\% CI $[-0.80$, $1.05]$, $t(18) = 0.28$, $p = .783$\"\n## \n## $table\n## NULL\n## \n## attr(,\"class\")\n## [1] \"apa_results\" \"list\""},{"path":"t-tests.html","id":"conceptual-i-simulating-the-t-test","chapter":"2 T-tests","heading":"2.4 Conceptual I: Simulating the t-test","text":"section create simulations various components independent samples t-test. One goal make code general, can simulate wide range designs.simulate experimental situation involving two groups B. assume equal number subjects (N), subject measured similar number times (X times). also simulate null-hypothesis, assumes experimental manipulation ineffective. result, assume subjects B randomly sampled underlying distribution. assume raw scores subject come normal distribution.","code":""},{"path":"t-tests.html","id":"simulating-a-single-experiment","chapter":"2 T-tests","heading":"2.4.1 Simulating a single experiment","text":"assumptions place, possible simulate results single experiment.one alternative, another example one-liner:","code":"\n#subjects per group\nN <- 10\n# measurements per subject\nX <- 2\n\n# distribution assumptions\nA_mean <- 100\nB_mean <- 100\n\nA_sd <- 25\nB_sd <- 25\nA_scores <- rnorm(N*X,A_mean,A_sd)\nB_scores <- rnorm(N*X,B_mean,B_sd)\n\nsim_data <- data.frame(groups = rep(c(\"A\",\"B\"),each = N*X),\n                       subjects = rep(rep(1:N,each = X),2),\n                       scores = c(A_scores,B_scores))\n\nlibrary(dplyr)## \n## Attaching package: 'dplyr'## The following objects are masked from 'package:stats':\n## \n##     filter, lag## The following objects are masked from 'package:base':\n## \n##     intersect, setdiff, setequal, union\nsubject_means <- sim_data %>%\n  group_by(groups,subjects) %>%\n  summarize(means = mean(scores), .groups = 'drop')\n\nt.test(means~groups, var.equal =TRUE,data = subject_means)## \n##  Two Sample t-test\n## \n## data:  means by groups\n## t = -0.1053, df = 18, p-value = 0.9173\n## alternative hypothesis: true difference in means is not equal to 0\n## 95 percent confidence interval:\n##  -18.03250  16.31124\n## sample estimates:\n## mean in group A mean in group B \n##        99.95637       100.81700\nt.test(replicate(N, mean(rnorm(X, A_mean, A_sd))),\n       replicate(N, mean(rnorm(X, B_mean, B_sd))),\n       var.equal = TRUE)## \n##  Two Sample t-test\n## \n## data:  replicate(N, mean(rnorm(X, A_mean, A_sd))) and replicate(N, mean(rnorm(X, B_mean, B_sd)))\n## t = -0.93814, df = 18, p-value = 0.3606\n## alternative hypothesis: true difference in means is not equal to 0\n## 95 percent confidence interval:\n##  -23.382884   8.946536\n## sample estimates:\n## mean of x mean of y \n##  101.0205  108.2386"},{"path":"t-tests.html","id":"simulating-distributions-of-experiments","chapter":"2 T-tests","heading":"2.4.2 Simulating distributions of experiments","text":"“experiment may regarded forming individual ‘population’ experiments might performed conditions. series experiments sample drawn population.” — William Sealy Gossett (Student, 1908).quote first sentence Student’s formative paper t-test. previous section simulated single experiment. conduct simulation several thousand times, can create “population” experiments occurred conditions. general idea create sampling distribution experiments, compare results actual experiment distributions possible experiments.","code":""},{"path":"t-tests.html","id":"the-distribution-of-mean-differences","chapter":"2 T-tests","heading":"2.4.2.1 The distribution of mean differences","text":"experiment repeated 1000 times, time mean difference Group B. Thus, mean difference sample statistic used summarize result experiment, sampling distribution mean differences estimated simulation:","code":"\nsim_mean_diffs <- replicate(1000, mean(replicate(N, mean(rnorm(X, A_mean, A_sd)))) - mean(replicate(N, mean(rnorm(X, B_mean, B_sd)))))\n\nhist(sim_mean_diffs)"},{"path":"t-tests.html","id":"the-distribution-of-t","chapter":"2 T-tests","heading":"2.4.2.2 The distribution of t","text":"Student used \\(t\\) formula, rather mean differences summarize sample data two group experiment. \\(t\\) formula normalizes mean difference estimated standard error mean.\\(t = \\frac{\\bar{X}_1 - \\bar{X}_2}{s_p\\sqrt{2/n}}\\)\\(s_p = \\sqrt{\\frac{s^2_{X_1} + s^2_{X_2}}{2}}\\)Although already distribution functions t-values, t-distribution constructed simulation. histogram 1000 \\(t\\) values happened.","code":"\nsim_ts <- replicate(1000, t.test(replicate(N, mean(rnorm(X, A_mean, A_sd))),\n                                 replicate(N, mean(rnorm(X, B_mean, B_sd))),\n                                 var.equal = TRUE)$statistic)\nhist(sim_ts)"},{"path":"t-tests.html","id":"t-distribution-functions","chapter":"2 T-tests","heading":"2.4.3 t distribution functions","text":"R comes dt, pt, qt, rt family function t-distributions well.example, rather simulating t values , sample 1000 \\(t\\) values t-distribution df = 18.\ndt function used draw probability density function t-distributions across range degrees freedom.discussed lecture, t-distribution approaches normal distribution degrees freedom increase. example, 95% values normal distribution smaller Z = 1.644854 standard deviations. corresponding 95% values t shown approach 1.644 degrees freedom increase.","code":"\nhist(rt(1000,df=18))\nlibrary(ggplot2)\nplot_df <- data.frame(values = c(dt(x=seq(-5,5,length.out = 100), df=1),\n                                 dt(x=seq(-5,5,length.out = 100), df=3),\n                                 dt(x=seq(-5,5,length.out = 100), df=5),\n                                 dt(x=seq(-5,5,length.out = 100), df=9),\n                                 dt(x=seq(-5,5,length.out = 100), df=11)\n                                 ),\n                      x = rep(seq(-5,5,length.out = 100),5),\n                      df = as.factor(rep(c(1,3,5,9,11), each = 100))\n                      )\n\nggplot(plot_df, aes(x = x, y=values, color=df, group=df))+\n  geom_line()+\n  ylab(\"density\")+\n  xlab(\"t\")+\n  scale_x_continuous(breaks=-5:5)\nqnorm(.95,0,1)## [1] 1.644854\nqt(p=.95,df=c(1,5,10,100,1000))## [1] 6.313752 2.015048 1.812461 1.660234 1.646379"},{"path":"t-tests.html","id":"conceptual-ii-simulating-power-curves","chapter":"2 T-tests","heading":"2.5 Conceptual II: Simulating power curves","text":"simulations assumed experimental manipulation effect, therefore expectation measurements groups taken distribution, differences groups explained random sampling.Another possibility experimental manipulation effective caused difference groups. case expectations measurements group different distributions. Specifically, causal force manipulation assumed change performance, resulting systematic changes scores group received manipulation. experimental manipulation principle change almost property distribution, differences means often focus research interest.","code":""},{"path":"t-tests.html","id":"what-proportion-of-experiments-would-be-significant","chapter":"2 T-tests","heading":"2.5.1 What proportion of experiments would be significant…?","text":"purpose conceptual section use simulation techniques ask proportion experiments significant (alpha level, say p<.05) experimental manipulation worked caused difference group means.First, confident basic answer. set alpha criterion p<.05, proportion experiments significant according null-hypothesis (difference groups)? can conduct simulation, see many experiments 1000 returned p-value less .05. answer , definition, approximately .05.next question something like, proportion experiments significant actually difference means group B. example, assume group mean 0, group B mean .25, distributions standard deviation (sd=1). design, N = 10 group, 5 scores measured per subject, probability getting p < .05 much higher 5%.","code":"\nsim_ps <- replicate(1000, t.test(replicate(10, mean(rnorm(5, 0, 1))),\n                                 replicate(10, mean(rnorm(5, 0, 1))),\n                                 var.equal = TRUE)$p.value)\nhist(sim_ps)\nlength(sim_ps[sim_ps < .05])/1000## [1] 0.035\nsim_ps <- replicate(1000, t.test(replicate(10, mean(rnorm(5, 0, 1))),\n                                 replicate(10, mean(rnorm(5, .25, 1))),\n                                 var.equal = TRUE)$p.value)\nhist(sim_ps)\nlength(sim_ps[sim_ps < .05])/1000## [1] 0.223"},{"path":"t-tests.html","id":"effect-size","chapter":"2 T-tests","heading":"2.5.2 Effect-size","text":"working toward plotting power-curves, show us probability getting significant result function design parameters like number subjects, number scores per subject (observations per cell), well assumed “effect-size” manipulation. Effect size regular meaning, idea experimental manipulation can cause change different amounts, manipulations might big effects (e.g., cause really big change mean), small effects.Effect-size can also refer specific statistical units. example, Cohen proposed effect-sizes mean differences two groups standardized. example, mean difference group B, clear big small difference. underlying distributions unit normal distributions, mean shift 1 large, represents shifting distribution whole standard deviation. underlying distributions large standard deviation, say 100, shifting mean 1 isn’t large respect total variability., Cohen’s effect size can expressed idea normalize mean difference standard deviation.\\(\\text{Cohen's d} = \\frac{\\text{mean difference}}{\\text{standard deviation}}\\)make use ideas power-curve simulations. Specifically, convenience, use unit normal distributions parent distributions group scores. , simulate differences mean groups. result, increase mean difference .25, .5, 1, another number, can interpret differences terms standard deviation units.","code":""},{"path":"t-tests.html","id":"power-curve-as-a-function-of-effect-size","chapter":"2 T-tests","heading":"2.5.3 Power-curve as a function of effect-size","text":"example conduct range simulations assuming effect-size increases 0 1.5, steps .1. simulations design parameters: N=10 subjects per group, X=5 scores taken subject. power curve shows proportion experiments return result p < .05 level effect-size. example, assumed effect-size 1, design detect effect size p<.05 level close 100% time. However, “power” design detect smaller effects decreases following curve.","code":"\neffect_sizes <- seq(0,1.5,.1)\nprop_significant <-c()\n\nfor(i in 1:length(effect_sizes)){\n  sim_ps <- replicate(1000, t.test(replicate(10, mean(rnorm(5, 0, 1))),\n                                   replicate(10, mean(rnorm(5, effect_sizes[i], 1))),\n                                   var.equal = TRUE)$p.value)\n  \n  prop_significant[i] <- length(sim_ps[sim_ps < .05])/1000\n}\n\nplot_df <- data.frame(effect_sizes,\n                      prop_significant)\n\nggplot(plot_df, aes(x=effect_sizes,y=prop_significant))+\n  geom_line() +\n  geom_point() +\n  scale_x_continuous(breaks=seq(0,1.5,.1))+\n  scale_y_continuous(breaks=seq(0,1,.1)) +\n  ylab(\"Proportion Significant\")"},{"path":"t-tests.html","id":"lab-10-generalization-assignment","chapter":"2 T-tests","heading":"2.6 Lab 10 Generalization Assignment","text":"","code":""},{"path":"t-tests.html","id":"instructions","chapter":"2 T-tests","heading":"2.6.1 Instructions","text":"general, labs present discussion problems issues example code like , students tasked completing generalization assignments, showing can work concepts tools independently.assignment instructions following:Work inside R project “StatsLab1” usingCreate new R Markdown document called “Lab10.Rmd”Use Lab10.Rmd show work attempting solve following generalization problems. Commit work regularly appears Github repository.problem, make note much problem believe can solve independently without help. example, needed watch help video unable solve problem without copying answers, note 0. confident can complete problem scratch completely , note 100. OK 0s 100s anything .Submit github repository link Lab 10 blackboard.","code":""},{"path":"t-tests.html","id":"problems","chapter":"2 T-tests","heading":"2.6.2 Problems","text":"task obtain data following paper conduct reproducible analysis results.Rosenbaum, D., Mama, Y., & Algom, D. (2017). Stand Stroop: Standing Enhances Selective Attention Cognitive Control. Psychological science, 28(12), 1864-1867.Note, paper, data, existing reproducible analysis data available https://crumplab.github.io/statisticsLab/lab-10-factorial-anova.html#important-stuff-4The re-analysis focus Experiment 3. three main goalsReproduce much analysis possible using paired-sample t-tests. Note, authors reported 2x2 repeated measures ANOVA, consider questions answered t-tests (2 points)Reproduce graph means, like shown paper (2 points)Present power-curve analysis design. (2 points)Note copy R markdown document described solution video can found github repository course: https://github.com/CrumpLab/psyc7709Lab/tree/master/lab_solutions","code":""},{"path":"t-tests.html","id":"references","chapter":"2 T-tests","heading":"2.7 References","text":"","code":""},{"path":"references-1.html","id":"references-1","chapter":"References","heading":"References","text":"Pearson, E. S. (1939). \"Student\" Statistician. Biometrika, 30(3/4), 210. https://doi.org/10/c2t7mzSawilowsky, S. S., & Blair, R. C. (1992). realistic look robustness type II error properties t test departures population normality. Psychological Bulletin, 111(2), 352. https://doi.org/10/bnxbp9Student. (1908). probable error mean. Biometrika, 1–25.","code":""}]
